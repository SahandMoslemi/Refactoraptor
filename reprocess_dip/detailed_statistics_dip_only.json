{
  "generation_timestamp": "2025-07-11T11:21:58.004421",
  "analysis_metadata": {
    "total_models_analyzed": 16,
    "violation_types_tested": [
      "dip"
    ],
    "prompt_strategies_tested": [
      "default",
      "ensemble",
      "example",
      "smell"
    ],
    "total_samples_processed": 768,
    "focus": "DIP (Dependency Inversion Principle) violations only"
  },
  "statistics": {
    "overall": {
      "precision": 1.0,
      "recall": 0.01953125,
      "f1_score": 0.038314176245210725,
      "accuracy": 0.01953125,
      "true_positives": 15,
      "false_positives": 0,
      "false_negatives": 753,
      "true_negatives": 0,
      "total_samples": 768
    },
    "by_violation_type": {
      "DIP": {
        "precision": 1.0,
        "recall": 0.01953125,
        "f1_score": 0.038314176245210725,
        "accuracy": 0.01953125,
        "true_positives": 15,
        "false_positives": 0,
        "false_negatives": 753,
        "true_negatives": 0,
        "total_samples": 768,
        "by_language": {
          "JAVA": {
            "precision": 1.0,
            "recall": 0.036458333333333336,
            "f1_score": 0.07035175879396986,
            "accuracy": 0.036458333333333336,
            "true_positives": 7,
            "false_positives": 0,
            "false_negatives": 185,
            "true_negatives": 0,
            "total_samples": 192
          },
          "PYTHON": {
            "precision": 1.0,
            "recall": 0.010416666666666666,
            "f1_score": 0.020618556701030924,
            "accuracy": 0.010416666666666666,
            "true_positives": 2,
            "false_positives": 0,
            "false_negatives": 190,
            "true_negatives": 0,
            "total_samples": 192
          },
          "KOTLIN": {
            "precision": 1.0,
            "recall": 0.005208333333333333,
            "f1_score": 0.010362694300518135,
            "accuracy": 0.005208333333333333,
            "true_positives": 1,
            "false_positives": 0,
            "false_negatives": 191,
            "true_negatives": 0,
            "total_samples": 192
          },
          "C#": {
            "precision": 1.0,
            "recall": 0.026041666666666668,
            "f1_score": 0.050761421319796954,
            "accuracy": 0.026041666666666668,
            "true_positives": 5,
            "false_positives": 0,
            "false_negatives": 187,
            "true_negatives": 0,
            "total_samples": 192
          }
        },
        "by_model": {
          "deepseek33b-temp0:latest": {
            "precision": 1.0,
            "recall": 0.005208333333333333,
            "f1_score": 0.010362694300518135,
            "accuracy": 0.005208333333333333,
            "true_positives": 1,
            "false_positives": 0,
            "false_negatives": 191,
            "true_negatives": 0,
            "total_samples": 192
          },
          "qwen2.5-coder32b-temp0:latest": {
            "precision": 1.0,
            "recall": 0.052083333333333336,
            "f1_score": 0.09900990099009901,
            "accuracy": 0.052083333333333336,
            "true_positives": 10,
            "false_positives": 0,
            "false_negatives": 182,
            "true_negatives": 0,
            "total_samples": 192
          },
          "codellama70b-temp0:latest": {
            "precision": 0.0,
            "recall": 0.0,
            "f1_score": 0.0,
            "accuracy": 0.0,
            "true_positives": 0,
            "false_positives": 0,
            "false_negatives": 192,
            "true_negatives": 0,
            "total_samples": 192
          },
          "gpt-4o-mini": {
            "precision": 1.0,
            "recall": 0.020833333333333332,
            "f1_score": 0.04081632653061225,
            "accuracy": 0.020833333333333332,
            "true_positives": 4,
            "false_positives": 0,
            "false_negatives": 188,
            "true_negatives": 0,
            "total_samples": 192
          }
        },
        "by_strategy": {
          "smell": {
            "precision": 0.0,
            "recall": 0.0,
            "f1_score": 0.0,
            "accuracy": 0.0,
            "true_positives": 0,
            "false_positives": 0,
            "false_negatives": 192,
            "true_negatives": 0,
            "total_samples": 192
          },
          "example": {
            "precision": 1.0,
            "recall": 0.0625,
            "f1_score": 0.11764705882352941,
            "accuracy": 0.0625,
            "true_positives": 12,
            "false_positives": 0,
            "false_negatives": 180,
            "true_negatives": 0,
            "total_samples": 192
          },
          "ensemble": {
            "precision": 1.0,
            "recall": 0.015625,
            "f1_score": 0.03076923076923077,
            "accuracy": 0.015625,
            "true_positives": 3,
            "false_positives": 0,
            "false_negatives": 189,
            "true_negatives": 0,
            "total_samples": 192
          },
          "default": {
            "precision": 0.0,
            "recall": 0.0,
            "f1_score": 0.0,
            "accuracy": 0.0,
            "true_positives": 0,
            "false_positives": 0,
            "false_negatives": 192,
            "true_negatives": 0,
            "total_samples": 192
          }
        }
      }
    },
    "summary": {
      "violation_analyzed": "DIP",
      "f1_score": 0.038314176245210725
    }
  }
}